{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Q1. **What is Elastic Net Regression and how does it differ from other regression techniques?**\n",
        "\n",
        "Elastic net regression is a linear regression technique that uses a penalty term to shrink the coefficients of the predictors. The penalty term is a combination of the l1-norm (absolute value) and the l2-norm (square) of the coefficients, weighted by a parameter called alpha. The l1-norm penalty is similar to lasso, which tends to produce sparse solutions by setting some coefficients to zero. The l2-norm penalty is similar to ridge, which tends to reduce the variance of the coefficients by shrinking them towards zero.\n",
        "\n",
        "**How does elastic net differ from lasso and ridge?**\n",
        "\n",
        "The main difference between elastic net and lasso or ridge is that elastic net has an additional parameter called lambda, which controls the balance between the l1-norm and the l2-norm penalties. When lambda is zero, elastic net is equivalent to lasso. When lambda is one, elastic net is equivalent to ridge. When lambda is between zero and one, elastic net is a compromise between lasso and ridge. This allows elastic net to adapt to different situations and data sets."
      ],
      "metadata": {
        "id": "F2kl2098pFJC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " Q2 How do you choose the optimal values of the regularization parameters for Elastic Net Regression?\n",
        "\n",
        " In addition to setting and choosing a lambda value elastic net also allows us to tune the alpha parameter where ùû™ = 0 corresponds to ridge and ùû™ = 1 to lasso. Simply put, if you plug in 0 for alpha, the penalty function reduces to the L1 (ridge) term and if we set alpha to 1 we get the L2 (lasso) term. Therefore we can choose an alpha value between 0 and 1 to optimize the elastic net. Effectively this will shrink some coefficients and set some to 0 for sparse selection."
      ],
      "metadata": {
        "id": "x1TaakuoskpD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q3.** What are the advantages and disadvantages of Elastic Net Regression?**\n",
        "\n",
        "**Advantages of elastic net regression**\n",
        "Elastic net regression has several advantages over lasso and ridge regression, depending on the data and the problem.\n",
        "\n",
        "For instance, it can handle multicollinearity better than lasso regression by grouping correlated features and selecting the most representative ones.\n",
        "\n",
        "Additionally, it can reduce model complexity by eliminating irrelevant features, which is more effective than ridge regression.\n",
        "\n",
        "Moreover, elastic net regression can achieve a better trade-off between bias and variance than lasso and ridge regression by tuning the regularization parameters.\n",
        "\n",
        "Furthermore, this type of regression can be applied to various types of data, such as linear, logistic, or Cox regression models.\n",
        "\n",
        "\n",
        "**Disadvantages of elastic net regression**\n",
        "\n",
        "Elastic net regression has some drawbacks compared to lasso and ridge regression, such as requiring more computational resources and time due to two regularization parameters and a cross-validation process.\n",
        "\n",
        " It may not perform optimally when there is no correlation between features or when the number of features is much smaller than the number of observations, as it may lose predictive power or introduce bias.\n",
        "\n",
        "  Additionally, it may not be easily interpretable, as it could select a large number of features with small coefficients or a small number of features with large coefficients."
      ],
      "metadata": {
        "id": "ofWfF3V3uyUo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q4. What are some common use cases for Elastic Net Regression?**\n",
        "\n",
        "Moreover, elastic net regression can achieve a better trade-off between bias and variance than lasso and ridge regression by tuning the regularization parameters. Furthermore, this type of regression can be applied to various types of data, such as linear, logistic, or Cox regression models."
      ],
      "metadata": {
        "id": "RDwBRV7av0tu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q5. How do you interpret the coefficients in Elastic Net Regression?**\n",
        "\n",
        "The coefficients of elastic net regression represent the linear relationship between the features and the target variable, adjusted by the regularization terms. The larger the absolute value of a coefficient, the stronger the effect of the corresponding feature on the target variable.\n",
        "\n",
        "The sign of a coefficient indicates the direction of the effect: positive for positive correlation, negative for negative correlation. The coefficients that are zero indicate that the corresponding features are not relevant for the model, and they are eliminated by the lasso penalty. Therefore, you can use the coefficients of elastic net regression to rank the features by their importance and select the ones that have non-zero coefficients."
      ],
      "metadata": {
        "id": "_FekCQeuwL3r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q6. How do you handle missing values when using Elastic Net Regression?**\n",
        "\n",
        "We can use different methods to handle missing data points, such as dropping missing values, imputing them using machine learning, or treating missing values as a separate category."
      ],
      "metadata": {
        "id": "4MZ55Py3wmgc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q7. How do you use Elastic Net Regression for feature selection?**\n",
        "\n",
        "\n",
        "The coefficients that are zero indicate that the corresponding features are not relevant for the model, and they are eliminated by the lasso penalty. Therefore, you can use the coefficients of elastic net regression to rank the features by their importance and select the ones that have non-zero coefficients."
      ],
      "metadata": {
        "id": "ggYFWjO9yf1Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q8. How do you pickle and unpickle a trained Elastic Net Regression model in Python?**\n",
        "\n",
        "Using pickle , simply save your model on disc with dump() function and de-pickle it into your python code with load() function. Use open() function to create and/or read from a . pkl file and make sure you open the file in the binary format by wb for write and rb for read mode."
      ],
      "metadata": {
        "id": "TuVRNMMcynCr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q9. What is the purpose of pickling a model in machine learning?**\n",
        "\n",
        "Pickle is a useful Python tool that allows you to save your ML models, to minimise lengthy re-training and allow you to share, commit, and re-load pre-trained machine learning models. Most data scientists working in ML will use Pickle or Joblib to save their ML model for future use."
      ],
      "metadata": {
        "id": "EvStR0Z8zldG"
      }
    }
  ]
}